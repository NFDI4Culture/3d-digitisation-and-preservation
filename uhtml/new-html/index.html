<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>3D Digitisation and Preservation</title>
    <link type="text/css" rel="stylesheet" href="css/book.css" />
    <style>
      a.fn {
        -adapt-template: url(data:application/xml,%3Chtml%20xmlns=%22http://www.w3.org/1999/xhtml%22%20xmlns:s=%22http://www.pyroxy.com/ns/shadow%22%3E%3Chead%3E%3Cstyle%3E.footnote-content%7Bfloat:footnote%7D%3C/style%3E%3C/head%3E%3Cbody%3E%3Cs:template%20id=%22footnote%22%3E%3Cs:content/%3E%3Cs:include%20class=%22footnote-content%22/%3E%3C/s:template%3E%3C/body%3E%3C/html%3E#footnote);
        text-decoration: none;
        color: inherit;
        vertical-align: baseline;
        font-size: 70%;
        position: relative;
        top: -0.3em;
      }
      body {
        background-color: white;
      }
      section[role=doc-footnote] .footnote-counter:after {
        content: ". ";
      }
      section.fnlist {
        display: none;
      }
      section:footnote-content {
        display: block;
        font-style: normal;
        font-weight: normal;
        text-decoration: none;
      }
      .table-of-contents a {
        display: inline-flex;
        width: 100%;
        text-decoration: none;
        color: currentColor;
        break-inside: avoid;
        align-items: baseline;
      }
      .table-of-contents a::before {
        margin-left: 1px;
        margin-right: 1px;
        border-bottom: solid 1px lightgray;
        content: "";
        order: 1;
        flex: auto;
      }
      .table-of-contents a::after {
        text-align: right;
        content: target-counter(attr(href, url), page);
        align-self: flex-end;
        flex: none;
        order: 2;
      }
      @page {
        size: A4;
        @top-center {
          content: env(doc-title);
        }
        @bottom-center {
          content: counter(page);
        }
      }
      @page :first {
        @bottom-center {
          content: normal;
        }
        @top-center {
          content: normal;
        }
      }
      figure img {
        max-width: 100%;
      }
      .article-title {
        page-break-before: right;
      }
      h1.part {
        page-break-before: right;
      }
      .copyrightpage {
        page-break-before: left;
      }
      .tocpage {
        page-break-before: right;
      }
      .booktitle {
        text-align: center;
      }
    </style>
    <link type="text/css" rel="stylesheet" href="css/nfdi4c-v1.css" />
  </head>
  <body class="user-contents">
    <div class="titlepage frontmatter">
      <h1 class="booktitle">3D Digitisation and Preservation</h1>
      <h2 class="booksubtitle">Survey Results from the NFDI4Culture Community</h2>
      <h3 class="bookauthor">by Jörg Heseler, Matthias Arnold, Alexandra Büttner and Simon Worthington</h3>
      <h4 class="bookversion">Version: 1.0.0, December 2023</h4>
    </div>
    <div class="copyrightpage frontmatter">
      <p>Published by: NFDI4Culture, Digital Publications and Data Working Group</p>
      <p>Last updated: 2023-11-29</p>
      <p>Created: 2023-10-04</p>
      <p>Language: English (United Kingdom)</p>
      <p>Created by: Editorial Team</p>
    </div>
    <div class="tocpage frontmatter">
      <nav role="doc-toc">
        <ol>
          <li>
            <a href="#_0_0">
              Survey results
            </a>
            <ol>
              <li>
                <a href="#H2166864">
                  Introduction
                </a>
              </li>
              <li>
                <a href="#H7382254">
                  Analysis
                </a>
                <ol>
                  <li>
                    <a href="#H3467047">
                      1. Participants and disciplines
                    </a>
                  </li>
                  <li>
                    <a href="#H5038832">
                      2. Digitisation methods
                    </a>
                  </li>
                  <li>
                    <a href="#H5099979">
                      3. Digitised objects
                    </a>
                  </li>
                  <li>
                    <a href="#H8923199">
                      4. Metadata schemas
                    </a>
                  </li>
                  <li>
                    <a href="#H3316673">
                      5. Digitisation software
                    </a>
                  </li>
                  <li>
                    <a href="#H706109">
                      6. Capture hardware
                    </a>
                  </li>
                  <li>
                    <a href="#H8737907">
                      7. Display devices for 3D data
                    </a>
                  </li>
                  <li>
                    <a href="#H4417931">
                      8. 3D formats
                    </a>
                  </li>
                  <li>
                    <a href="#H8422827">
                      9. 3D data viewing software
                    </a>
                  </li>
                </ol>
              </li>
              <li>
                <a href="#H5820587">
                  Conclusion and outlook
                </a>
              </li>
              <li>
                <a href="#H1115470">
                  Appendix: Survey data
                </a>
              </li>
              <li>
                <a href="#H3740076">
                  Acknowledgements
                </a>
              </li>
            </ol>
          </li>
          <li>
            <a href="#_1_0">
              Imprint
            </a>
          </li>
        </ol>
      </nav>
    </div>
    <div class="article-part article-title" id="_0_0">Survey results</div>
    <div class="article-part article-richtext article-body">
      <h2 id="H2166864"><span class="comment" data-id="3424945378"><span class="comment" data-id="4028345909">I</span></span>ntroduction</h2>
      <p>One of the project goals of <a href="https://nfdi4culture.de/" title="https://nfdi4culture.de/">NFDI4Culture – Consortium for Research Data on Material and Immaterial Cultural Heritage</a> and specifically the <a href="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html">Task Area Data Publication and Availability</a> (TA4) is the development of concepts for central long term preservation services to ensure a sustainable infrastructure. In particular, publications from cultural disciplines with 3D data are in the foreground. The requirements for developing a concept are the needs of producers, providers and administrators of research data. One measure of this needs assessment was the implementation of a survey on the creation, use and handling of 3D models, the results of which are discussed below.</p>
      <h2 id="H7382254">Analysis</h2>
      <h3 id="H3467047">1. Participants and disciplines</h3>
      <p>This survey on 3D digitisation and long-term preservation was conducted during the <a href="https://nfdi4culture.de/news-events/events/forum-3d-digital-preservation.html">NFDI4Culture Forum "3D objects: digitisation, presentation and preservation"</a> in May 2022. This forum was jointly organized by the task areas <a href="https://nfdi4culture.de/about-us/task-areas/task-area-1" title="https://nfdi4culture.de/about-us/task-areas/task-area-1">Data capture and enrichment of digital cultural assets</a> (TA1) and <a href="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html" title="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html">Data publication and data availability</a> (TA4). The aim of the event was to support the exchange between 3D data providers and repository operators in order to identify needs and problems and to work together to solve them in the future. The main goal of this survey was to identify used file formats and metadata schemas in the 3D area used by the NFDI4Culture communities, i.e. media and music studies as well as architecture, art history and performing arts.</p>
      <figure id="F66192711" class="aligned-center image-width-75" data-aligned="center" data-width="75" data-category="figure"><img src="images/1bf2bbbd-149e-42e3-9688-5349c2230a9c.png">
        <figcaption><span class="label-counter" data-book-counter="1" data-chapter-counter="1">Figure</span><span class="text">Which discipline would you classify yourself as?</span></figcaption>
      </figure>
      <p>First, we asked about the disciplines to which the respondents belong. Nine out of twenty participants (45%) assigned themselves to NFDI4Culture disciplines. Of these, architecture was most frequently represented with 17.5%, followed by art studies with 15%, media studies with 10% and dance studies with 2.5%. Participants were able to assign themselves to several specialist areas. No other personal data was collected.</p>
      <h3 id="H5038832">2. Digitisation methods</h3>
      <figure id="F63452571" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/bbb7b6d7-4f35-47b5-8a84-feb030ab8986.png">
        <figcaption><span class="label-counter" data-book-counter="2" data-chapter-counter="2">Figure</span><span class="text">Which methods do you use to digitise 3D objects<span class="comment" data-id="2546594093">?</span></span></figcaption>
      </figure>
      <p>When asked which digitisation methods our participants used, photogrammetry was used fifteen times, followed by strip light methods eleven times, laser scanning methods nine times, as well as terrain models seven times, structure-from-motion (SfM) and computer tomography (CT) four times each, as well as terrestrial laser scanning (TLS) and Reflectance Transformation Imaging (RTI) twice each. Finally, the modeling of abstract models such as molecules but also the use of X-ray were mentioned once each.</p>
      <h3 id="H5099979">3. Digitised objects</h3>
      <figure id="F59599821" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/b5bdeea8-8f9e-4632-90ec-2753eee6fed4.png">
        <figcaption><span class="label-counter" data-book-counter="3" data-chapter-counter="3">Figure</span><span class="text">What are you digitising? (Ordered by object size)</span></figcaption>
      </figure>
      <p>With regard to the objects to be digitised, the variety in terms of size, material and surface structure was significant. Museum objects were frequently listed, from pottery to sculptures made from various materials such as ceramics or metal. Very large objects such as buildings and landscapes followed, which were mostly mentioned in connection with capture using stationary laser scanners or drones using photogrammetry methods. In addition to the previously mentioned modeled molecules, very small objects such as insects, fossils or even bones were also listed, for which CT or X-ray methods were mainly used.</p>
      <h3 id="H8923199">4. Metadata schemas</h3>
      <figure id="F40902971" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/40c087a1-cf6e-4777-923f-47081040a36a.png">
        <figcaption><span class="label-counter" data-book-counter="4" data-chapter-counter="4">Figure</span><span class="text">Which metadata schemas do you use?</span></figcaption>
      </figure>
      <p>When asked about the metadata schemas used to describe the physical and digital objects, the XML schema Lightweight Information Describing Objects (LIDO) was mentioned twice and Dublin Core, Simple Knowledge Organization System (SKOS), Conceptual Reference Model of the International Council (CIDOC), DataCite, Data Catalog Vocabulary (DCAT) and a metadata schema by Homburg et al. once each. Data representation forms or concepts for structuring bibliographic information were also occasionally listed, which will not be discussed further here.</p>
      <p>Finally, four respondents reported not using metadata schemas. One participant also stated that they were unfamiliar with the term metadata schema. Furthermore, seven participants did not provide any information on this question.</p>
      <h3 id="H3316673">5. Digitisation software</h3>
      <figure id="F33020721" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/986ca241-eb10-4b0a-921c-9abe923b8cff.png">
        <figcaption><span class="label-counter" data-book-counter="5" data-chapter-counter="5">Figure</span><span class="text">What software do you use to digitise 3D objects?</span></figcaption>
      </figure>
      <p>Regarding 3D digitisation software, 3D scanning and photogrammetry, 3D scan analysis, modeling software and a game engine, as well as 3D reverse engineering, documentation and 2D image processing software were mentioned. Artec Studio was listed as 3D scanning software six times, followed by GOM ATOS and Leica Cyclone three times each, and 3D scanning software from the Fraunhofer Institute for Graphical Data Processing twice. Isra Vision Polymetric, OPTOCAT, Autodesk ReCap Photo, VXelements, Geomagic Wrap and 3D scanning software from Zeiss and Z+F were also listed once each. In terms of photogrammetry software, Agisoft Metashape was mentioned eleven times, Meshroom four times, RealityCapture twice and 3DF Zephyr once. In addition, the 3D analysis tool GOM Inspect was listed twice. Finally, the 3D modeling software Blender and Autodesk 3ds Max, the CAD modeling software Autodesk AutoCAD, the game engine Unity, the 3D reverse engineering software Geomagic Design X, the documentation software TroveSketch and the 2D image processing software darktable followed once each.</p>
      <h3 id="H706109">6. Capture hardware</h3>
      <figure id="F31967781" class="aligned-center image-width-75" data-aligned="center" data-width="75" data-category="figure"><img src="images/e609af1f-59c3-44ab-89d5-a415c30b2502.png">
        <figcaption><span class="label-counter" data-book-counter="6" data-chapter-counter="6">Figure</span><span class="text">What hardware do you use to capture 3D objects?</span></figcaption>
      </figure>
      <p>In terms of hardware for object detection, stationary scanners were mentioned fifteen times, which primarily work with laser light and are used for medium to large objects. In addition, hand-held scanners were listed six times, particularly for detecting small to medium-sized objects, which use striped light or laser scanning methods. The use of drones to capture buildings and landscapes was mentioned five times. A Reflectance Transformation Imaging (RTI) dome scanner was also used to capture small to medium-sized objects. Furthermore, nine single-lens reflex (SLR) and two mirrorless cameras were listed, with which photos were taken either for documentation purposes or to calculate 3D models using photogrammetric methods.</p>
      <h3 id="H8737907">7. Display devices for 3D data</h3>
      <figure id="F49406191" class="aligned-center image-width-75" data-aligned="center" data-width="75" data-category="figure"><img src="images/b876bc22-1039-49f1-8fe3-955562aa4d03.png">
        <figcaption><span class="label-counter" data-book-counter="7" data-chapter-counter="7">Figure</span><span class="text">Do you use special hardware to display your 3D data?</span></figcaption>
      </figure>
      <p>Six participants stated that they did not use any special devices to display 3D data. Apart from that, virtual reality (VR) glasses were mentioned four times, including the Oculus Rift glasses twice and the Oculus Quest and HTC Vive once each. The augmented reality (AR) glasses Microsoft Hololens were also listed twice. An Apple iPad tablet and a Multi-touch table were also mentioned once each.</p>
      <h3 id="H4417931">8. 3D formats</h3>
      <figure id="F14202431" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/ddd4c2fd-8640-460c-9ec3-b4a795109ead.png">
        <figcaption><span class="label-counter" data-book-counter="8" data-chapter-counter="8">Figure</span><span class="text">Which 3D formats do you work with for digitisation, presentation or digital preservation?</span></figcaption>
      </figure>
      <p>The most important question for us in this survey was which 3D formats the community uses for various application scenarios, such as digitisation, presentation and digital long-term archiving. The participants listed Wavefront OBJ twelve times, Stanford Polygon (PLY) six times, Filmbox (FBX) and Stereolithography (STL) four times each, Graphics Language Transmission Format (GLTF or the binary variant GLB) and Extensible 3D (X3D) twice each. In addition to the 3D format Nexus (NXS or the compressed variant NXZ), the Industry Foundation Classes (IFC) format, which is common in construction, as well as the point cloud format XYZ and general CT formats were each mentioned once.</p>
      <h3 id="H8422827">9. 3D data viewing software</h3>
      <figure id="F86260851" class="aligned-center image-width-100" data-aligned="center" data-width="100" data-category="figure"><img src="images/3f2c7bb4-fde7-4859-b423-4beb309f1730.png">
        <figcaption><span class="label-counter" data-book-counter="9" data-chapter-counter="9">Figure</span><span class="text">Do you use special software to display your 3D data?</span></figcaption>
      </figure>
      <p>Finally, we asked&nbsp;what software is used to display 3D data. MeshLab was listed six times, the 3DHOP Viewer, which is based on the Nexus adaptive 3D viewer, three times, and CloudCompare twice. The RTIViewer, GigaMesh, Smithsonian Voyager, the Babylon Viewer and the kompakkt viewer, which is based on the Babylon.js framework, were also mentioned once. A viewer from the Fraunhofer Institute for Graphical Computing as well as GOM Inspect and SketchFab were also listed. One participant reported using an own WebGL-based viewer.</p>
      <h2 id="H5820587">Conclusion and outlook</h2>
      <p>This survey gave us valuable insight into the formats, devices and software used by our community for 3D digitisation and long-term archiving. This lays the foundation for further investigations and developments.</p>
      <p>A first interesting aspect of this survey was the question about the use of metadata schemas. It remains unclear why seven out of twenty participants (35%) did not provide any information here. In addition, current metadata schemas, e.g. CARARE or Extensible Metadata Platform (XMP), were not mentioned. The latter raises the question of the extent to which existing schemas for 3D data are accepted by the community and meet their needs. To better understand this, a deeper study of this topic would be required.</p>
      <p>A second interesting aspect was the question of 3D formats used. Formats such as Extensible 3D (X3D) and Graphics Language Transmission Format (GLTF) or Digital Asset Exchange (DAE) are particularly suitable for long-term archiving due to their high degree of disclosure, self-documentation and timeliness. However, these were only mentioned in the minority or the latter was not mentioned. Formats that are not suitable for long-term archiving were also listed: Filmbox (FBX) is a proprietary format, which means that there is no openly available format specification that describes the exact structure of an FBX file. If this format ceases to be widely used in the future, long-term archives may not be able to develop their own tools for rendering or converting FBX files. In the case of Nexus (NXS or NXZ), the distribution is too low to ensure that there will still be tools that can display this format in 20 years. In the text-based point cloud format XYZ, the data structure is not clear, which is why this format is unsuitable for software-independent exchange. The standardised ASTM E57 format would be an alternative to the long-term archiving of 3D point clouds. However, we have not yet examined CT formats for their archivability. Finally, the information provided by the participants also showed that, on the one hand, when querying formats in further surveys, we must differentiate between the purposes and, on the other hand, continue to point out the advantages of 3D formats that can be archived for a long time.</p>
      <p>It is also noticeable that the 3D scanning software used is largely proprietary and device-specific. Likewise, most of the photogrammetry software used is not freely accessible. However, the large number of open source viewers mentioned for displaying 3D data is positive.</p>
      <p>Future surveys will expand on these findings and focus on specific 3D use cases in addition to long-term preservation purposes. To draw general conclusions, it is crucial to reach a larger number of participants and better understand their specific backgrounds and needs.</p>
      <p>Finally, it is planned to create a guide for the digital long-term archiving of 3D cultural heritage objects based on collected findings and further investigations. This guide will help establish good practices in the NFDI4Culture communities and promote collaboration between different actors in the field of cultural heritage.</p>
      <h2 id="H1115470">Appendix: Survey data</h2>
      <p>Anonymised survey source data: <br><a href="https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data" title="https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data">https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data</a></p>
      <h2 id="H3740076">Acknowledgements</h2>
      <p>The authors would like to thank all participants for their valuable contributions and commitment to this survey. Your insights will help advance the future of 3D digitisation and long-term preservation of cultural heritage objects. We would also like to thank the following colleagues for their helpful comments: Eva Bodenschatz and Sabrina Herzog.</p>
    </div>
    <section class="fnlist" role="doc-footnotes"></section>
    <div class="article-part article-title" id="_1_0">Imprint</div>
    <div class="article-part article-richtext article-body">
      <figure id="F23178491" class="aligned-left image-width-25" data-aligned="left" data-width="25" data-category="none" data-caption-hidden="true"><img src="images/c311788f-07f7-4a45-9b48-1eac0238ff7a.png"></figure>
      <p>        </p>
      <p><br>NFDI4Culture – Consortium for Research Data on Material and Immaterial Cultural Heritage, <a href="https://nfdi4culture.de/">https://nfdi4culture.de/</a><br></p>
      <p>         </p>
      <p>         </p>
      <p>         </p>
      <p><strong>Authors</strong>:</p>
      <p>Heseler, Jörg; ORCID iD: <a href="https://orcid.org/0000-0002-1497-627X">0000-0002-1497-627X</a>; Saxon State and University Library Dresden (SLUB Dresden); ROR ID: <a href="https://ror.org/03wf51b65">https://ror.org/03wf51b65</a></p>
      <p>Arnold, Matthias; ORCID iD: <a href="https://orcid.org/0000-0003-0876-6177">0000-0003-0876-6177</a>; Ruprecht-Karls-Universität Heidelberg, Universitätsbibliothek; ROR ID: <a href="https://ror.org/038t36y30">https://ror.org/038t36y30</a></p>
      <p>Büttner, Alexandra; ORCID iD: <a href="https://orcid.org/0000-0002-4950-0941">0000-0002-4950-0941</a>; Ruprecht-Karls-Universität Heidelberg, Universitätsbibliothek; ROR ID: <a href="https://ror.org/038t36y30">https://ror.org/038t36y30</a></p>
      <p>Worthington, Simon; ORCID iD: <a href="https://orcid.org/0000-0002-8579-9717">0000-0002-8579-9717</a>; German National Library of Science and Technology (TIB); ROR ID: <a href="https://ror.org/04aj4c181">https://ror.org/04aj4c181</a></p>
      <p><strong>Citation</strong>:</p>
      <p>Heseler, Jörg; Arnold, Matthias; Büttner, Alexandra; &amp; Worthington, Simon. (2023). <em>3D Digitisation and Preservation – Survey Results from the NFDI4Culture Community</em>. Digital Publications and Data Working Group (NFDI4Culture). <a href="https://doi.org/10.5281/zenodo.8033413">https://doi.org/10.5281/zenodo.8033413</a>.</p>
      <p>German version: Heseler, Jörg; Arnold, Matthias; Büttner, Alexandra; &amp; Worthington, Simon. (2023). <em>3D-Digitalisierung und Langzeitarchivierung – Umfrageergebnisse aus der NFDI4Culture Community</em>. Arbeitsgruppe Digitale Publikationen und Daten (NFDI4Culture). <a href="https://doi.org/10.5281/zenodo.8033536">https://doi.org/10.5281/zenodo.8033536</a>.</p>
      <p><strong><br>HTML version</strong>:</p>
      <p><a href="https://nfdi4culture.github.io/3d-digitisation-and-preservation/" title="3D Digitisation and Preservation">https://nfdi4culture.github.io/3d-digitisation-and-preservation<span class="comment" data-id="3174531947"><span class="comment" data-id="902889231">/</span></span></a></p>
      <p>German version: <a href="https://nfdi4culture.github.io/3d-digitalisierung-und-langzeitarchivierung/" title="3D-Digitalisierung und Langzeitarchivierung">https://nfdi4culture.github.io/3d-digitalisierung-und-langzeitarchivierung/</a></p>
      <p><strong>Keywords</strong>:</p>
      <p><a href="https://www.wikidata.org/wiki/Q98276929" title="https://www.wikidata.org/wiki/Q98276929">NFDI4Culture</a>; <a href="https://www.wikidata.org/wiki/Q3490295" title="https://www.wikidata.org/wiki/Q3490295">survey</a>; <a href="https://www.wikidata.org/wiki/Q3859833" title="https://www.wikidata.org/wiki/Q3859833">3d model</a>; <a href="https://www.wikidata.org/wiki/Q35459920" title="https://www.wikidata.org/wiki/Q35459920">3d object</a>; <a href="https://www.wikidata.org/wiki/Q632897" title="https://www.wikidata.org/wiki/Q632897">digital preservation</a>; <a href="https://www.wikidata.org/wiki/Q843958" title="https://www.wikidata.org/wiki/Q843958">digitisation</a>; <a href="https://www.wikidata.org/wiki/Q15809982" title="https://www.wikidata.org/wiki/Q15809982">research data</a>; <a href="https://www.wikidata.org/wiki/Q41623316" title="https://www.wikidata.org/wiki/Q41623316">metadata scheme</a>; <a href="https://www.wikidata.org/wiki/Q235557" title="https://www.wikidata.org/wiki/Q235557">file format</a></p>
      <p><strong>Funding</strong>:</p>
      <p>NFDI4Culture and this research are funded by the German Research Foundation (DFG) under project number <a href="https://gepris.dfg.de/gepris/projekt/441958017">441958017</a>.</p>
      <p>DFG: <a href="https://www.dfg.de/" title="https://www.dfg.de/">https://www.dfg.de/</a>; ROR ID: <a href="https://ror.org/018mejw64">https://ror.org/018mejw64</a>&nbsp;</p>
      <p><strong>Licenses</strong>:</p>
      <figure id="F79920841" class="aligned-left image-width-25" data-aligned="left" data-width="25" data-category="none" data-caption-hidden="true"><img src="images/a25da50e-a434-4a58-a212-8effd5900985.png"></figure>
      <p>        </p>
      <p>This work is licensed under a <a href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</p>
      <p>        </p>
      <p>© Copyright of the texts: The Authors, 2023.&nbsp;</p>
      <p><strong>Fonts</strong>:</p>
      <p>Inter. These fonts are licensed under the <a href="https://github.com/rsms/inter/blob/master/LICENSE.txt">SIL Open Font License, Version 1.1</a>. The Inter project is led by Rasmus Andersson. <a href="https://github.com/rsms/inter/">https://github.com/rsms/inter/</a></p>
      <p>Playfair Display. These fonts are licensed under the <a href="https://github.com/clauseggers/Playfair/blob/master/OFL.txt" title="https://github.com/clauseggers/Playfair/blob/master/OFL.txt">SIL Open Font License, Version 1.1</a>. Designer is Claus Eggers Sørensen. <a href="https://github.com/clauseggers/Playfair">https://github.com/clauseggers/Playfair</a></p>
      <p>Roboto Slab. These fonts are licensed under the <a href="https://github.com/googlefonts/robotoslab/blob/main/LICENSE.txt" title="https://github.com/googlefonts/robotoslab/blob/main/LICENSE.txt">Apache License, Version 2.0</a>. Designer is Christian Robertson. <a href="https://github.com/googlefonts/robotoslab">https://github.com/googlefonts/robotoslab</a>        </p>
      <p><strong>Technical information</strong>:</p>
      <p>ADA Semantic Publishing Pipeline: <a href="https://github.com/NFDI4Culture/ADA-semantic-publishing">https://github.com/NFDI4Culture/ADA-semantic-publishing</a>&nbsp;</p>
      <p>Multi-format CSS theming: <a href="https://interpunct.dev/">Interpunct.de<span class="comment" data-id="3040007768"><span class="comment" data-id="3424945378">v</span></span></a></p>
      <p></p>
      <p></p>
      <h3 id="H664724"></h3>
    </div>
    <section class="fnlist" role="doc-footnotes"></section>
  </body>
</html>