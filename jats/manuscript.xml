<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2 20190208//EN" "https://jats.nlm.nih.gov/archiving/1.2/JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:ali="http://www.niso.org/schemas/ali/1.0/"><front><article-meta><article-categories></article-categories><title-group><article-title>3D Digitisation and Preservation</article-title></title-group><permissions/></article-meta></front><body id="body"><sec id="h-1"><sec id="H161717"><title>Survey Results from the NFDI4Culture Community</title><p id="p-1">Version: 1.0.0, December 2023</p><p id="p-2">Jörg Heseler, Matthias Arnold, Alexandra Büttner and Simon Worthington</p></sec></sec><sec id="H5078228"><title>Survey results</title><sec id="H2166864"><title>Introduction</title><p id="p-3">One of the project goals of <ext-link xlink:href="https://nfdi4culture.de/" ext-link-type="uri" xlink:title="https://nfdi4culture.de/">NFDI4Culture – Consortium for Research Data on Material and Immaterial Cultural Heritage</ext-link> and specifically the <ext-link xlink:href="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html" ext-link-type="uri" xlink:title="null">Task Area Data Publication and Availability</ext-link> (TA4) is the development of concepts for central long term preservation services to ensure a sustainable infrastructure. In particular, publications from cultural disciplines with 3D data are in the foreground. The requirements for developing a concept are the needs of producers, providers and administrators of research data. One measure of this needs assessment was the implementation of a survey on the creation, use and handling of 3D models, the results of which are discussed below.</p></sec><sec id="H7382254"><title>Analysis</title><sec id="H3467047"><title>1. Participants and disciplines</title><p id="p-4">This survey on 3D digitisation and long-term preservation was conducted during the <ext-link xlink:href="https://nfdi4culture.de/news-events/events/forum-3d-digital-preservation.html" ext-link-type="uri" xlink:title="null">NFDI4Culture Forum &quot;3D objects: digitisation, presentation and preservation&quot;</ext-link> in May 2022. This forum was jointly organized by the task areas <ext-link xlink:href="https://nfdi4culture.de/about-us/task-areas/task-area-1" ext-link-type="uri" xlink:title="https://nfdi4culture.de/about-us/task-areas/task-area-1">Data capture and enrichment of digital cultural assets</ext-link> (TA1) and <ext-link xlink:href="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html" ext-link-type="uri" xlink:title="https://nfdi4culture.de/what-we-do/task-areas/task-area-4.html">Data publication and data availability</ext-link> (TA4). The aim of the event was to support the exchange between 3D data providers and repository operators in order to identify needs and problems and to work together to solve them in the future. The main goal of this survey was to identify used file formats and metadata schemas in the 3D area used by the NFDI4Culture communities, i.e. media and music studies as well as architecture, art history and performing arts.</p><fig id="F66192711"><label>Figure 1</label><caption><p>Which discipline would you classify yourself as?</p></caption><graphic position="anchor" xlink:href="1bf2bbbd-149e-42e3-9688-5349c2230a9c.png"/></fig><p id="p-5">First, we asked about the disciplines to which the respondents belong. Nine out of twenty participants (45%) assigned themselves to NFDI4Culture disciplines. Of these, architecture was most frequently represented with 17.5%, followed by art studies with 15%, media studies with 10% and dance studies with 2.5%. Participants were able to assign themselves to several specialist areas. No other personal data was collected.</p></sec><sec id="H5038832"><title>2. Digitisation methods</title><fig id="F63452571"><label>Figure 2</label><caption><p>Which methods do you use to digitise 3D objects?</p></caption><graphic position="anchor" xlink:href="aef67e4d-ba8d-4c3b-aa93-180538ce8521.png"/></fig><p id="p-6">When asked which digitisation methods our participants used, photogrammetry was used fifteen times, followed by strip light methods eleven times, laser scanning methods nine times, as well as terrain models seven times, structure-from-motion (SfM) and computer tomography (CT) four times each, as well as terrestrial laser scanning (TLS) and Reflectance Transformation Imaging (RTI) twice each. Finally, the modeling of abstract models such as molecules but also the use of X-ray were mentioned once each.</p></sec><sec id="H5099979"><title>3. Digitised objects</title><fig id="F59599821"><label>Figure 3</label><caption><p>What are you digitising? (Ordered by object size)</p></caption><graphic position="anchor" xlink:href="084455be-e7eb-4935-bd26-9fa048184f34.png"/></fig><p id="p-7">With regard to the objects to be digitised, the variety in terms of size, material and surface structure was significant. Museum objects were frequently listed, from pottery to sculptures made from various materials such as ceramics or metal. Very large objects such as buildings and landscapes followed, which were mostly mentioned in connection with capture using stationary laser scanners or drones using photogrammetry methods. In addition to the previously mentioned modeled molecules, very small objects such as insects, fossils or even bones were also listed, for which CT or X-ray methods were mainly used.</p></sec><sec id="H8923199"><title>4. Metadata schemas</title><fig id="F40902971"><label>Figure 4</label><caption><p>Which metadata schemas do you use?</p></caption><graphic position="anchor" xlink:href="d7e233d1-915f-4c52-b3d1-18e93e78f9bb.png"/></fig><p id="p-8">When asked about the metadata schemas used to describe the physical and digital objects, the XML schema Lightweight Information Describing Objects (LIDO) was mentioned twice and Dublin Core, Simple Knowledge Organization System (SKOS), Conceptual Reference Model of the International Council (CIDOC), DataCite, Data Catalog Vocabulary (DCAT) and a metadata schema by Homburg et al. once each. Data representation forms or concepts for structuring bibliographic information were also occasionally listed, which will not be discussed further here.</p><p id="p-9">Finally, four respondents reported not using metadata schemas. One participant also stated that they were unfamiliar with the term metadata schema. Furthermore, seven participants did not provide any information on this question.</p></sec><sec id="H3316673"><title>5. Digitisation software</title><fig id="F33020721"><label>Figure 5</label><caption><p>What software do you use to digitise 3D objects?</p></caption><graphic position="anchor" xlink:href="2550bf43-a8fe-4b6c-a001-791f697a389f.png"/></fig><p id="p-10">Regarding 3D digitisation software, 3D scanning and photogrammetry, 3D scan analysis, modeling software and a game engine, as well as 3D reverse engineering, documentation and 2D image processing software were mentioned. Artec Studio was listed as 3D scanning software six times, followed by GOM ATOS and Leica Cyclone three times each, and 3D scanning software from the Fraunhofer Institute for Graphical Data Processing twice. Isra Vision Polymetric, OPTOCAT, Autodesk ReCap Photo, VXelements, Geomagic Wrap and 3D scanning software from Zeiss and Z+F were also listed once each. In terms of photogrammetry software, Agisoft Metashape was mentioned eleven times, Meshroom four times, RealityCapture twice and 3DF Zephyr once. In addition, the 3D analysis tool GOM Inspect was listed twice. Finally, the 3D modeling software Blender and Autodesk 3ds Max, the CAD modeling software Autodesk AutoCAD, the game engine Unity, the 3D reverse engineering software Geomagic Design X, the documentation software TroveSketch and the 2D image processing software darktable followed once each.</p></sec><sec id="H706109"><title>6. Capture hardware</title><fig id="F31967781"><label>Figure 6</label><caption><p>What hardware do you use to capture 3D objects?</p></caption><graphic position="anchor" xlink:href="7fe98d36-3707-4ceb-ba63-6642e4d9e92f.png"/></fig><p id="p-11">In terms of hardware for object detection, stationary scanners were mentioned fifteen times, which primarily work with laser light and are used for medium to large objects. In addition, hand-held scanners were listed six times, particularly for detecting small to medium-sized objects, which use striped light or laser scanning methods. The use of drones to capture buildings and landscapes was mentioned five times. A Reflectance Transformation Imaging (RTI) dome scanner was also used to capture small to medium-sized objects. Furthermore, nine single-lens reflex (SLR) and two mirrorless cameras were listed, with which photos were taken either for documentation purposes or to calculate 3D models using photogrammetric methods.</p></sec><sec id="H8737907"><title>7. Display devices for 3D data</title><fig id="F49406191"><label>Figure 7</label><caption><p>Do you use special hardware to display your 3D data?</p></caption><graphic position="anchor" xlink:href="97c278a4-7b53-4dd3-934f-4a56bd896a84.png"/></fig><p id="p-12">Six participants stated that they did not use any special devices to display 3D data. Apart from that, virtual reality (VR) glasses were mentioned four times, including the Oculus Rift glasses twice and the Oculus Quest and HTC Vive once each. The augmented reality (AR) glasses Microsoft Hololens were also listed twice. An Apple iPad tablet and a Multi-touch table were also mentioned once each.</p></sec><sec id="H4417931"><title>8. 3D formats</title><fig id="F14202431"><label>Figure 8</label><caption><p>Which 3D formats do you work with for digitisation, presentation or digital preservation?</p></caption><graphic position="anchor" xlink:href="63735e55-48b7-439f-a25a-84402f27007d.png"/></fig><p id="p-13">The most important question for us in this survey was which 3D formats the community uses for various application scenarios, such as digitisation, presentation and digital long-term archiving. The participants listed Wavefront OBJ twelve times, Stanford Polygon (PLY) six times, Filmbox (FBX) and Stereolithography (STL) four times each, Graphics Language Transmission Format (GLTF or the binary variant GLB) and Extensible 3D (X3D) twice each. In addition to the 3D format Nexus (NXS or the compressed variant NXZ), the Industry Foundation Classes (IFC) format, which is common in construction, as well as the point cloud format XYZ and general CT formats were each mentioned once.</p></sec><sec id="H8422827"><title>9. 3D data viewing software</title><fig id="F86260851"><label>Figure 9</label><caption><p>Do you use special software to display your 3D data?</p></caption><graphic position="anchor" xlink:href="3f2c7bb4-fde7-4859-b423-4beb309f1730.png"/></fig><p id="p-14">Finally, we asked what software is used to display 3D data. MeshLab was listed six times, the 3DHOP Viewer, which is based on the Nexus adaptive 3D viewer, three times, and CloudCompare twice. The RTIViewer, GigaMesh, Smithsonian Voyager, the Babylon Viewer and the kompakkt viewer, which is based on the Babylon.js framework, were also mentioned once. A viewer from the Fraunhofer Institute for Graphical Computing as well as GOM Inspect and SketchFab were also listed. One participant reported using an own WebGL-based viewer.</p></sec></sec><sec id="H5820587"><title>Conclusion and outlook</title><p id="p-15">This survey gave us valuable insight into the formats, devices and software used by our community for 3D digitisation and long-term archiving. This lays the foundation for further investigations and developments.</p><p id="p-16">A first interesting aspect of this survey was the question about the use of metadata schemas. It remains unclear why seven out of twenty participants (35%) did not provide any information here. In addition, current metadata schemas, e.g. CARARE or Extensible Metadata Platform (XMP), were not mentioned. The latter raises the question of the extent to which existing schemas for 3D data are accepted by the community and meet their needs. To better understand this, a deeper study of this topic would be required.</p><p id="p-17">A second interesting aspect was the question of 3D formats used. Formats such as Extensible 3D (X3D) and Graphics Language Transmission Format (GLTF) or Digital Asset Exchange (DAE) are particularly suitable for long-term archiving due to their high degree of disclosure, self-documentation and timeliness. However, these were only mentioned in the minority or the latter was not mentioned. Formats that are not suitable for long-term archiving were also listed: Filmbox (FBX) is a proprietary format, which means that there is no openly available format specification that describes the exact structure of an FBX file. If this format ceases to be widely used in the future, long-term archives may not be able to develop their own tools for rendering or converting FBX files. In the case of Nexus (NXS or NXZ), the distribution is too low to ensure that there will still be tools that can display this format in 20 years. In the text-based point cloud format XYZ, the data structure is not clear, which is why this format is unsuitable for software-independent exchange. The standardised ASTM E57 format would be an alternative to the long-term archiving of 3D point clouds. However, we have not yet examined CT formats for their archivability. Finally, the information provided by the participants also showed that, on the one hand, when querying formats in further surveys, we must differentiate between the purposes and, on the other hand, continue to point out the advantages of 3D formats that can be archived for a long time.</p><p id="p-18">It is also noticeable that the 3D scanning software used is largely proprietary and device-specific. Likewise, most of the photogrammetry software used is not freely accessible. However, the large number of open source viewers mentioned for displaying 3D data is positive.</p><p id="p-19">Future surveys will expand on these findings and focus on specific 3D use cases in addition to long-term preservation purposes. To draw general conclusions, it is crucial to reach a larger number of participants and better understand their specific backgrounds and needs.</p><p id="p-20">Finally, it is planned to create a guide for the digital long-term archiving of 3D cultural heritage objects based on collected findings and further investigations. This guide will help establish good practices in the NFDI4Culture communities and promote collaboration between different actors in the field of cultural heritage.</p></sec><sec id="H1115470"><title>Appendix: Survey data</title><p id="p-21">Anonymised survey source data: <bold><break /></bold><ext-link xlink:href="https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data" ext-link-type="uri" xlink:title="https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data">https://github.com/NFDI4Culture/3d-digitalisierung-und-langzeitarchivierung/tree/main/survey-data</ext-link></p></sec><sec id="H3740076"><title>Acknowledgements</title><p id="p-22">The authors would like to thank all participants for their valuable contributions and commitment to this survey. Your insights will help advance the future of 3D digitisation and long-term preservation of cultural heritage objects. We would also like to thank the following colleagues for their helpful comments: Eva Bodenschatz and Sabrina Herzog.</p></sec></sec><sec id="H4184928"><title>Imprint</title><graphic id="F23178491" position="anchor" xlink:href="c311788f-07f7-4a45-9b48-1eac0238ff7a.png"/><p id="p-23">        </p><p id="p-24"><bold><break /></bold>NFDI4Culture – Consortium for Research Data on Material and Immaterial Cultural Heritage, <ext-link xlink:href="https://nfdi4culture.de/" ext-link-type="uri" xlink:title="null">https://nfdi4culture.de/</ext-link></p><p id="p-25">         </p><p id="p-26">         </p><p id="p-27">         </p><p id="p-28"><bold>Authors</bold>:</p><p id="p-29">Heseler, Jörg; ORCID iD: <ext-link xlink:href="https://orcid.org/0000-0002-1497-627X" ext-link-type="uri" xlink:title="null">0000-0002-1497-627X</ext-link>; Saxon State and University Library Dresden (SLUB Dresden); ROR ID: <ext-link xlink:href="https://ror.org/03wf51b65" ext-link-type="uri" xlink:title="null">https://ror.org/03wf51b65</ext-link></p><p id="p-30">Arnold, Matthias; ORCID iD: <ext-link xlink:href="https://orcid.org/0000-0003-0876-6177" ext-link-type="uri" xlink:title="null">0000-0003-0876-6177</ext-link>; Ruprecht-Karls-Universität Heidelberg, Universitätsbibliothek; ROR ID: <ext-link xlink:href="https://ror.org/038t36y30" ext-link-type="uri" xlink:title="null">https://ror.org/038t36y30</ext-link></p><p id="p-31">Büttner, Alexandra; ORCID iD: <ext-link xlink:href="https://orcid.org/0000-0002-4950-0941" ext-link-type="uri" xlink:title="null">0000-0002-4950-0941</ext-link>; Ruprecht-Karls-Universität Heidelberg, Universitätsbibliothek; ROR ID: <ext-link xlink:href="https://ror.org/038t36y30" ext-link-type="uri" xlink:title="null">https://ror.org/038t36y30</ext-link></p><p id="p-32">Worthington, Simon; ORCID iD: <ext-link xlink:href="https://orcid.org/0000-0002-8579-9717" ext-link-type="uri" xlink:title="null">0000-0002-8579-9717</ext-link>; German National Library of Science and Technology (TIB); ROR ID: <ext-link xlink:href="https://ror.org/04aj4c181" ext-link-type="uri" xlink:title="null">https://ror.org/04aj4c181</ext-link></p><p id="p-33"><bold>Citation</bold>:</p><p id="p-34">Heseler, Jörg; Arnold, Matthias; Büttner, Alexandra; &amp; Worthington, Simon. (2023). <italic>3D Digitisation and Preservation – Survey Results from the NFDI4Culture Community</italic>. Digital Publications and Data Working Group (NFDI4Culture). <ext-link xlink:href="https://doi.org/10.5281/zenodo.8033413" ext-link-type="uri" xlink:title="null">https://doi.org/10.5281/zenodo.8033413</ext-link>.</p><p id="p-35">German version: Heseler, Jörg; Arnold, Matthias; Büttner, Alexandra; &amp; Worthington, Simon. (2023). <italic>3D-Digitalisierung und Langzeitarchivierung – Umfrageergebnisse aus der NFDI4Culture Community</italic>. Arbeitsgruppe Digitale Publikationen und Daten (NFDI4Culture). <ext-link xlink:href="https://doi.org/10.5281/zenodo.8033536" ext-link-type="uri" xlink:title="null">https://doi.org/10.5281/zenodo.8033536</ext-link>.</p><p id="p-36"><bold><break /></bold><bold>HTML version</bold>:</p><p id="p-37"><ext-link xlink:href="https://nfdi4culture.github.io/3d-digitisation-and-preservation/" ext-link-type="uri" xlink:title="3D Digitisation and Preservation">https://nfdi4culture.github.io/3d-digitisation-and-preservation</ext-link><ext-link xlink:href="https://nfdi4culture.github.io/3d-digitisation-and-preservation/" ext-link-type="uri" xlink:title="3D Digitisation and Preservation">/</ext-link></p><p id="p-38">German version: <ext-link xlink:href="https://nfdi4culture.github.io/3d-digitalisierung-und-langzeitarchivierung/" ext-link-type="uri" xlink:title="3D-Digitalisierung und Langzeitarchivierung">https://nfdi4culture.github.io/3d-digitalisierung-und-langzeitarchivierung/</ext-link></p><p id="p-39"><bold>Keywords</bold>:</p><p id="p-40"><ext-link xlink:href="https://www.wikidata.org/wiki/Q98276929" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q98276929">NFDI4Culture</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q3490295" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q3490295">survey</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q3859833" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q3859833">3d model</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q35459920" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q35459920">3d object</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q632897" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q632897">digital preservation</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q843958" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q843958">digitisation</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q15809982" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q15809982">research data</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q41623316" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q41623316">metadata scheme</ext-link>; <ext-link xlink:href="https://www.wikidata.org/wiki/Q235557" ext-link-type="uri" xlink:title="https://www.wikidata.org/wiki/Q235557">file format</ext-link></p><p id="p-41"><bold>Funding</bold>:</p><p id="p-42">NFDI4Culture and this research are funded by the German Research Foundation (DFG) under project number <ext-link xlink:href="https://gepris.dfg.de/gepris/projekt/441958017" ext-link-type="uri" xlink:title="null">441958017</ext-link>.</p><p id="p-43">DFG: <ext-link xlink:href="https://www.dfg.de/" ext-link-type="uri" xlink:title="https://www.dfg.de/">https://www.dfg.de/</ext-link>; ROR ID: <ext-link xlink:href="https://ror.org/018mejw64" ext-link-type="uri" xlink:title="null">https://ror.org/018mejw64</ext-link> </p><p id="p-44"><bold>Licenses</bold>:</p><graphic id="F79920841" position="anchor" xlink:href="69c01099-4714-4b9e-9ba1-38dafc42b283.png"/><p id="p-45">        </p><p id="p-46">This work is licensed under a <ext-link xlink:href="https://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:title="null">Creative Commons Attribution 4.0 International License</ext-link>.</p><p id="p-47">        </p><p id="p-48">© Copyright of the texts: The Authors, 2023. </p><p id="p-49"><bold>Fonts</bold>:</p><p id="p-50">Inter. These fonts are licensed under the <ext-link xlink:href="https://github.com/rsms/inter/blob/master/LICENSE.txt" ext-link-type="uri" xlink:title="null">SIL Open Font License, Version 1.1</ext-link>. The Inter project is led by Rasmus Andersson. <ext-link xlink:href="https://github.com/rsms/inter/" ext-link-type="uri" xlink:title="null">https://github.com/rsms/inter/</ext-link></p><p id="p-51">Playfair Display. These fonts are licensed under the <ext-link xlink:href="https://github.com/clauseggers/Playfair/blob/master/OFL.txt" ext-link-type="uri" xlink:title="https://github.com/clauseggers/Playfair/blob/master/OFL.txt">SIL Open Font License, Version 1.1</ext-link>. Designer is Claus Eggers Sørensen. <ext-link xlink:href="https://github.com/clauseggers/Playfair" ext-link-type="uri" xlink:title="null">https://github.com/clauseggers/Playfair</ext-link></p><p id="p-52">Roboto Slab. These fonts are licensed under the <ext-link xlink:href="https://github.com/googlefonts/robotoslab/blob/main/LICENSE.txt" ext-link-type="uri" xlink:title="https://github.com/googlefonts/robotoslab/blob/main/LICENSE.txt">Apache License, Version 2.0</ext-link>. Designer is Christian Robertson. <ext-link xlink:href="https://github.com/googlefonts/robotoslab" ext-link-type="uri" xlink:title="null">https://github.com/googlefonts/robotoslab</ext-link>        </p><p id="p-53"><bold>Technical information</bold>:</p><p id="p-54">ADA Semantic Publishing Pipeline: <ext-link xlink:href="https://github.com/NFDI4Culture/ADA-semantic-publishing" ext-link-type="uri" xlink:title="null">https://github.com/NFDI4Culture/ADA-semantic-publishing</ext-link> </p><p id="p-55">Multi-format CSS theming: <ext-link xlink:href="https://interpunct.dev/" ext-link-type="uri" xlink:title="null">Interpunct.de</ext-link><ext-link xlink:href="https://interpunct.dev/" ext-link-type="uri" xlink:title="null">v</ext-link></p></sec></body><back></back></article>